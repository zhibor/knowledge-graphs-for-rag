{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Construct With Cypher\n",
    "\n",
    "Can the entire knowledge graph construction happen with Cypher? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Common data processing\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load from environment\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "\n",
    "print(f\"Connecting to Neo4j at {NEO4J_URI} as {NEO4J_USERNAME}\")\n",
    "\n",
    "DATA_URL = os.getenv('DATA_URL')\n",
    "\n",
    "if (DATA_URL is None): \n",
    "    print(\"No DATA_URL environment variable set. Please set this to the URL of the data to be loaded.\")\n",
    "    exit(1)\n",
    "\n",
    "print(f\"Loading data from {DATA_URL}\")\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if (OPENAI_API_KEY is None): \n",
    "    print(\"No OPENAI_API_KEY environment variable set. Please set this to the OpenAI API key.\")\n",
    "    exit(1)\n",
    "    \n",
    "# Create a knowledge graph using Langchain's Neo4j integration.\n",
    "# This will be used for direct querying of the knowledge graph. \n",
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")\n",
    "\n",
    "def checkPlugin(pluginName):\n",
    "    pluginFunctions = kg.query('''\n",
    "        SHOW FUNCTIONS yield name\n",
    "        WHERE name STARTS WITH $pluginName''', \n",
    "    params={'pluginName': pluginName})\n",
    "\n",
    "    pluginProcedures = kg.query('''\n",
    "        SHOW PROCEDURES yield name\n",
    "        WHERE name STARTS WITH $pluginName''', \n",
    "    params={'pluginName': pluginName})\n",
    "\n",
    "    if (len(pluginFunctions) == 0) and (len(pluginProcedures) == 0):\n",
    "        print(f\"No {pluginName} procedures or functions found. Has the {pluginName} plugin been installed and enabled?\")\n",
    "        exit(1)\n",
    "\n",
    "checkPlugin('gds')\n",
    "checkPlugin('genai')\n",
    "checkPlugin('apoc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset the graph, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all constraints and indexes\n",
    "for constraint in kg.query('SHOW CONSTRAINTS'):\n",
    "    kg.query(f\"DROP CONSTRAINT {constraint['name']}\")\n",
    "\n",
    "for index in kg.query('SHOW INDEXES'):\n",
    "    print(f\"Removing index {index['name']}:\")\n",
    "    kg.query(f\"\"\"\n",
    "        DROP INDEX `{index['name']}`\n",
    "    \"\"\")\n",
    "\n",
    "# Remove all nodes and relationships\n",
    "kg.query(\"\"\"\n",
    "        MATCH (all)\n",
    "        DETACH DELETE all\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Form10-k files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a uniqueness constraint on the formdId property of Form nodes \n",
    "kg.query('CREATE CONSTRAINT unique_form IF NOT EXISTS FOR (n:Form) REQUIRE n.formId IS UNIQUE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form10KFiles = [\n",
    "    '0000106040-23-000024.json',\n",
    "    '0000320187-23-000039.json',\n",
    "    '0000950170-23-027948.json',\n",
    "    '0000950170-23-033201.json',\n",
    "    '0001096906-23-001489.json',\n",
    "    '0001137789-23-000049.json',\n",
    "    '0001327567-23-000024.json',\n",
    "    '0001558370-23-011516.json',\n",
    "    '0001564708-23-000368.json',\n",
    "    '0001650372-23-000040.json'\n",
    "]\n",
    "\n",
    "for form10KFile in form10KFiles:\n",
    "    form10kUrl = f\"{DATA_URL}form10k/{form10KFile}\"\n",
    "    print(f\"Loading {form10kUrl}\")\n",
    "    kg.query(\"\"\"\n",
    "      WITH apoc.text.regexGroups($URL,'([^\\/]*)\\.json')[0][1] AS formId\n",
    "      CALL apoc.load.json($URL) YIELD value\n",
    "      MERGE (f:Form {formId: formId}) \n",
    "        ON CREATE SET f = value, f.formId = formId\n",
    "    \"\"\",\n",
    "    params={'URL': form10kUrl})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all text into separate chunk nodes. these are \"mega chunks\" that are not yet split\n",
    "for item in ['item1','item1a','item7','item7a']:\n",
    "  # note this is using a string template to insert the item name into the query\n",
    "  # icky but convenient here because we can't parameterize a property key\n",
    "  kg.query(f\"\"\"\n",
    "  MATCH (f:Form)\n",
    "  WITH f, \"0000\" as chunkSeqId\n",
    "  WITH f, chunkSeqId, f.formId + \"-{item}-chunk\" + chunkSeqId as chunkId\n",
    "  MERGE (section:Chunk {{chunkId: chunkId}})\n",
    "  ON CREATE SET \n",
    "      section.chunkSeqId = chunkSeqId,\n",
    "      section.text = f.{item}\n",
    "  MERGE (f)-[:SECTION {{f10kItem: \"{item}\"}}]->(section)\n",
    "  \"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the chunks into a linked list of smaller chunks\n",
    "kg.query(\"\"\"\n",
    "MATCH (f:Form)-[s:SECTION]->(first:Chunk)\n",
    "WITH f, s, first\n",
    "WITH f, s, first, apoc.text.split(first.text, \"\\s+\") as tokens\n",
    "CALL apoc.coll.partition(tokens, 1000) YIELD value\n",
    "WITH f, s, first, apoc.text.join(value, \" \") as chunk\n",
    "WITH f, s, first, collect(chunk) as chunks\n",
    "CALL {\n",
    "    WITH f, s, first, chunks\n",
    "    WITH f, s, first, chunks, [idx in range(1, size(chunks) -1) | \n",
    "         { chunkId: f.formId + \"-\" + s.f10kItem + \"-chunk\" + apoc.number.format(idx, \"#0000\"), text: chunks[idx] }] as chunkProps \n",
    "    CALL apoc.create.nodes([\"Chunk\"], chunkProps) yield node\n",
    "    SET first.text = head(chunks)\n",
    "    MERGE (node)-[:PART_OF]->(f)\n",
    "    WITH first, collect(node) as chunkNodes\n",
    "    CALL apoc.nodes.link(chunkNodes, 'NEXT')\n",
    "    WITH first, head(chunkNodes) as nextNode\n",
    "    MERGE (first)-[:NEXT]->(nextNode)\n",
    "}\n",
    "RETURN f.formId\n",
    " \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
    "          FOR (c:Chunk) ON (c.textEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 1536,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector embeddings for all the Chunk text, in batches.\n",
    "# Use this for larger number of chunks so that the query\n",
    "# can be re-run without losing all progress\n",
    "kg.query(\"\"\"\n",
    "  MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "  CALL {\n",
    "    WITH chunk\n",
    "    WITH chunk, genai.vector.encode(chunk.text, \"OpenAI\", {token: $openAiApiKey}) AS vector\n",
    "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)    \n",
    "  } IN TRANSACTIONS OF 10 ROWS\n",
    "  \"\"\", \n",
    "  params={\"openAiApiKey\":OPENAI_API_KEY} \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import form 13 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a uniqueness constraint on the cusip6 property of Company nodes \n",
    "kg.query(\"\"\"\n",
    "    CREATE CONSTRAINT unique_company \n",
    "        IF NOT EXISTS FOR (com:Company) \n",
    "        REQUIRE com.cusip6 IS UNIQUE\n",
    "\"\"\")\n",
    "\n",
    "# Create a uniqueness constraint on the managerCik property of Manager nodes \n",
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_manager \n",
    "  IF NOT EXISTS\n",
    "  FOR (n:Manager) \n",
    "  REQUIRE n.managerCik IS UNIQUE\n",
    "\"\"\")\n",
    "# Create a full-text index of Manager names\n",
    "kg.query(\"\"\"\n",
    "CREATE FULLTEXT INDEX fullTextManagerNames\n",
    "  IF NOT EXISTS\n",
    "  FOR (mgr:Manager) \n",
    "  ON EACH [mgr.managerName]\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "LOAD CSV WITH HEADERS FROM $URL as row\n",
    "MERGE (com:Company {cusip6: row.cusip6})\n",
    "  ON CREATE SET com.companyName = row.companyName,\n",
    "                com.cusip = row.cusip\n",
    "MERGE (mgr:Manager {managerCik: row.managerCik})\n",
    "    ON CREATE SET mgr.managerName = row.managerName,\n",
    "            mgr.managerAddress = row.managerAddress\n",
    "MERGE (mgr)-[owns:OWNS_STOCK_IN { \n",
    "    reportCalendarOrQuarter: row.reportCalendarOrQuarter }]->(com)\n",
    "    ON CREATE\n",
    "      SET owns.value  = toFloat(row.value), \n",
    "          owns.shares = toInteger(row.shares)\n",
    "\"\"\",\n",
    "params={'URL': DATA_URL + \"form13.csv\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect all `Company` nodes to their corresponding `Form` nodes\n",
    "# based on the `cusip6` property\n",
    "kg.query(\"\"\"\n",
    "  MATCH (com:Company), (form:Form)\n",
    "    WHERE com.cusip6 = form.cusip6\n",
    "  SET com.names = form.names\n",
    "  MERGE (com)-[:FILED]->(form)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
